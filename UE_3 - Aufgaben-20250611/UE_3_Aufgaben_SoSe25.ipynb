{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uebung 3 Merkmalsextraktion, binaere Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel dieser Übung ist die Integration der erlernten **Merkmalsextraktionsverfahren** in eine Klassifikationspipeline. Die einzelnen Schritte sind in der folgenden Abbildung veranschaulicht.\n",
    "\n",
    "Dabei werdet ihr euch zunächst einmal der Unterscheidung von jeweils **zwei Klassen** widmen, also binären Klassifikationsproblemen. Nachdem ihr alle Aufgaben gelöst habt, könnt ihr die Anwendung für alle Klassen erweitern.\n",
    "\n",
    "Das primäre Ziel ist der Aufbau einer **funktionierenden** Klassifikationspipeline und die Evaluation der Ergebnisse. Fokussiert euch zunächst auf die Implementierung. Wenn ihr alle Schritte implementiert und die Ergebnisse evaluiert habt, könnt ihr euch Gedanken über die Optimierung der Ergebnisse machen. \n",
    "\n",
    "Ihr werdet einen Subset aus dem **Industrial 100** Datensatz verwenden. Der Subset enthält die ersten 15 Klassen des Datensatzes. Eine Übersicht über alle ClassIDs und deren Bezeichnungen findet ihr in der csv-Datei **Industrial100-labels.csv**.\n",
    "\n",
    "\n",
    "Den Datensatz könnt ihr von der tubCloud herunterladen und in den BGA2-Ordner ablegen (oder auf eurem eigenen Rechner). Anbei der **Link zum Datensatz**: https://tubcloud.tu-berlin.de/s/7ZRADfF4kdJGSma\n",
    "\n",
    "**WICHTIG:** Die Daten aus diesem Subset solltet ihr nicht für die Hausaufgabe verwenden!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./ipynb_bilder/klassifikationspipeline.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog, sift\n",
    "from skimage import exposure\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import learning_curve, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score, precision_score, precision_recall_curve\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenexploration\n",
    "1. Schaut euch die ersten fünfzehn Klassen des Datensatzes \"Industrial 100\" an. Nutzt dafür euer Vorwissen (optional auch Hilfsfunktionen) aus Übung 1. Wählt für euch eine geeignete Methode (z.B. interaktive Anzeige mit ipywidgets.interact oder pyplot.subplots), um die 15 Klassen mitsamt ClassIDs und deren Bezeichnungen zu visualisieren. Ein Bild pro Klasse ist ausreichend. \n",
    "2. Wählt zwei Klassen aus, mit denen ihr die Klassifikationspipeline aufbaut. Dies könnt ihr im Laufe der Übung variieren, um schwierigere und leichtere Klassifikationsprobleme zu untersuchen, je nachdem ob die Klassen sehr ähnlich sind oder sich sehr unterscheiden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merkmalsextraktion\n",
    "1. Extrahiert die [HOG](https://scikit-image.org/docs/0.20.x/auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py)-Features für die von euch ausgewählten Klassen. Erweitert dafür euer Code aus Übung 2 so, dass ihr Features aus allen Bildern der beiden Klassen extrahiert.  \n",
    "2. Unterteilt die Daten in Trainings- und Validierungsdaten. Ein mögliches Verhältnis wäre z.B. 75% Trainingsdaten und 25% Validierungsdaten. Dafür könnt ihr beispielsweise die [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)-Funktion aus der scikit-learn-Bibliothek nutzen. \n",
    "3. Nachdem ihr alle Schritte der Klassifikationspipeline für HOG-Features implementiert habt, könnt ihr zu dieser Teilaufgabe zurückkehren und die SIFT-Features extrahieren und die Klassifikationspipeline mit SIFT-Features aufbauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinwese\n",
    "\n",
    "**Zu 1.** \n",
    "Um die Arbeitsspeicherprobleme zu vermeiden, legt euch eine Liste mit den Bildpfaden der jeweiligen Ordner an. Für Merkmalsextraktion könnt ihr eine for-Schleife nutzen, um die Bilder einzeln einzulesen. \n",
    "\n",
    "**WICHTIG**: Bevor ihr Merkmale extrahiert, sollt ihr Bilder skalieren (z.B. mit resize), so dass sie gleich groß sind.\n",
    "\n",
    "Speichert die extrahierten Merkmalsvektoren, damit sie diese nicht jedes Mal generieren müsst (siehe beigefügte Code Snippets)\n",
    "\n",
    "**Zu 2.** \n",
    "Um die train_test_split-Funktion zu benutzen, solltet ihr zusätzlicht zu den Merkmalsvektoren, die ihr generiert habt, die Label- (ClassID-)Vektoren anlegen. \n",
    "\n",
    "Überprüft nach dem Nutzen der train_test_split-Funktion, dass alle Vektorgrößen übereinstimmen (siehe beigefügte Code Snippets)\n",
    "\n",
    "Beispiel (bezieht sich nicht auf den Übungsdatensatz):\n",
    "\n",
    "\n",
    "Shape of \n",
    "- X_train_img: (1800, 1568) (1800 - Anzahl der Merkmalsvektoren, 1568 - Länge des Merkmalsvektors)\n",
    "- X_test_img: (600, 1568) \n",
    "- y_train_img: (1800,) \n",
    "- y_test_img: (600,)\n",
    "\n",
    "### Code Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save extracted features as numpy array\n",
    "# to do: change the variable names according to your code\n",
    "with open('hog_features_labels_all_classes.npy', 'wb') as f:\n",
    "    np.save(f, np.array(hog_featutes_list))\n",
    "    np.save(f, np.array(class_labels_list))\n",
    "    np.save(f, np.array(img_paths))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved variables\n",
    "with open('hog_features_labels_all_classes.npy', 'rb') as f:\n",
    "    a = np.load(f)\n",
    "    b = np.load(f)\n",
    "    c = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of train and teat arrays after usage of train_test_split-function\n",
    "# to do: change the variable names according to your code\n",
    "print('Shape of \\nX_train_img: {} \\\n",
    "\\nX_test_img: {} \\ny_train_img: {} \\\n",
    "\\ny_test_img: {}'.format(X_train_img.shape, \\\n",
    "X_test_img.shape, y_train_img.shape, y_test_img.shape))\n",
    "\n",
    "# the code does not work for lists only for numpy arrays\n",
    "# see the following link to get the shape of a list:\n",
    "\n",
    "# https://sparkbyexamples.com/python/get-shape-of-list-in-python/\n",
    "# num_rows list\n",
    "len(my_list)\n",
    "# num_columns list\n",
    "len(my_list[0])\n",
    "print(np.shape(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "Führt eine PCA auf den Daten aus und projiziert die Daten dann in den neuen Merkmalsraum. Das gibt euch Aufschluss darüber, wie schwierig euer Klassifikationsproblem ist beziehungsweise wie gut eure Features geeignet sind, um die Klassen zu unterscheiden. \n",
    "\n",
    "Unter folgendem [Link](https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-lda-py) findet ihr ein Beispiel (2D PCA für den Iris-Datensatz)\n",
    "\n",
    "Nachdem ihr alle Schritte der Klassifikationspipeline implementiert und eure Ergebnisse evaluiert habt, könnt ihr die Klassifikation mit den durch die PCA reduzierten Feature-Vektoren durchführen und die Ergebnisse mit den Ergebnissen ohne PCA vergleichen. \n",
    "Konntet ihr die Unterschiede feststellen?\n",
    "\n",
    "### Hinweise \n",
    "PCA - theoretische Grundlagen und Implementierung in Python einfach erklärt:\n",
    "- https://www.youtube.com/watch?v=FgakZw6K1QQ\n",
    "- https://www.youtube.com/watch?v=Lsue2gEM9D0\n",
    "\n",
    "\n",
    "### Code Snippet\n",
    "#If 0 < n_components < 1 and svd_solver == 'full', \n",
    "#select the number of components such that the amount of variance \n",
    "#that needs to be explained is greater than the percentage specified by n_components.\n",
    "\n",
    "\n",
    "- pca_70 = PCA(n_components=.70, svd_solver='full')\n",
    "- pca_70.fit(feature_data_hog)\n",
    "- pca_70.n_components_\n",
    "- pca_70.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anbei ein Codesnippet für die Berechung und für die Visualisierung der PCA für die ersten zwei Hauptkomponenten \n",
    "# TO DO: definiere X- und y-Variablen\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "X2D = pca.fit_transform(X)\n",
    "plt.xlabel('first principal component')\n",
    "plt.ylabel('second principal component')\n",
    "plt.title('Plot 1')\n",
    "plt.scatter(X2D[:, 0], X2D[:, 1],c=y, cmap=plt.cm.nipy_spectral,edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation\n",
    "Für diese Teilaufgabe könnt ihr [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) Klassifikator, \n",
    " [SVM](https://scikit-learn.org/stable/modules/svm.html)-Klassifikator oder [MLP](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)-Klassifikator der scikit-learn-Bibliothek ausprobieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendungsbeispiel für Naive Bayes Klassifikator\n",
    "gnb = GaussianNB()\n",
    "# TO DO: Passe die Input- und Output-Parameter entsprechend den von dir gewählten Variablennamen an \n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Zur Beurteilung der Klassifikationsleistung des Klassifikators könnt ihr die CCR auf den Validierungsdaten berechnen und euch die Konfusionsmatrix anschauen. Dafür könnt ihr beispielsweise die [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)-Funktion, die [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion#sklearn.metrics.confusion_matrix)-Funktion, [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)-Funktion der scikit-learn-Bibliothek nutzen. Experimentiert ein wenig und vergleicht die Ergebnisse für verschiedene Klassen und Konfigurationen eures Klassifikators.\n",
    "\n",
    "\n",
    "Optional: Erstellung der Lernkurve\n",
    "Das Ziel ist, zu schauen, wie sich die Fehler auf den Trainings- und Validierungsdaten mit der Menge der genutzten Trainingsdaten verändern. Dies wird Aufschluss darüber geben, wie ihr eure Klassifikationsleistung am effektivsten verbessern könnt. Man kann daraus ablesen, ob z.B. die Features ungeeignet sind oder das Modell des Klassifikators zu simpel ist, oder ob z.B. mehr Trainingsdaten helfen würden um die Klassifikationsleistung zu verbessern. Zur Erstellung der Lernkurve könnt ihr die [learning_curve](https://scikit-learn.org/stable/modules/learning_curve.html#learning-curve)-Funktion der scikit-learn-Bibliothek nutzen.\n",
    "\n",
    "Nach dem Bearbeiten dieser Aufgabe sollt ihr folgende Fehlermaße / Gütekriterien definieren können und erklären, wofür sie verwendet werden: \n",
    "- accuracy score\n",
    "- confusion matrix\n",
    "- f1 score\n",
    "- true positives\n",
    "- true negatives\n",
    "- false positives\n",
    "- false negatives\n",
    "- precision\n",
    "- recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Passe die Input- und Output-Parameter entsprechend den von dir gewählten Variablennamen an \n",
    "accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score for Classes X & Y is: {}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Passe die Input- und Output-Parameter entsprechend den von dir gewählten Variablennamen an \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Passe die Input- und Output-Parameter entsprechend den von dir gewählten Variablennamen an \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "Schaut euch die [scikit-learn-Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) an, um die Ergebnisse zu interpretieren. Achtet dabei auf die Implementierung des **average**-Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Passe die Input- und Output-Parameter entsprechend den von dir gewählten Variablennamen an \n",
    "# Untersuche die Unterschiede für average='macro', average='micro', average='weighted', average=None\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision / Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Passe die Input- und Output-Parameter entsprechend den von dir gewählten Variablennamen an \n",
    "# Untersuche die Unterschiede für average='macro', average='micro', average='weighted', average=None\n",
    "# Link zur scikit-learn Doku: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "precision_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link zur scikit-learn Doku: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\n",
    "recall_score(y_test, y_pred, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
