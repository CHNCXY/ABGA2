{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab0e04c",
   "metadata": {},
   "source": [
    "# √úbung 2 Merkmalsextraktionsverfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed614e",
   "metadata": {},
   "source": [
    "In dieser √úbungseinheit werdet ihr unterschiedliche Merkmalsextraktionsverfahren implementieren.\n",
    "\n",
    "F√ºr die Bearbeitung dieser Aufgabe ben√∂tigt ihr theoretische Kenntnisse f√ºr die folgenden Themen: \n",
    "- **Harris Corner Detector** \n",
    "- **HOG-Features** \n",
    "- **SIFT**\n",
    "\n",
    "\n",
    "**Ziel**: \n",
    "Im Zuge der Bearbeitung dieser Aufgabe soll ein tieferes Verst√§ndnis der Funktionsweise der oben genannten  Merkmalsextraktionsverfahren erlangt werden.\n",
    "\n",
    "**Daten**:\n",
    "Nutzt f√ºr die Implementierung der Merkmalsextraktionsverfahren die im Ordner \"Bilder\" abgelegten Bilddaten (2 - 3 Bilder pro Teilaufgabe).\n",
    "\n",
    "Beispielbilder der implementierten Verfahren (von links nach rechts): Graustufenbild, Graustufenbild mit Harris-Keypoints, Visualisierung der HOG-Features, Graustufenbild mit SIFT-Keypoints\n",
    "\n",
    "\n",
    "<img src=\"./ipynb_bilder/stop_example.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5bcd6",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb766dc3",
   "metadata": {},
   "source": [
    "**Hinweis Installation von scikit-image-Paket**\n",
    "\n",
    "F√ºr diejenigen, die auf den eingenen Rechnern arbeiten: scikit-image-Paket \n",
    "√ºber das Terminal / anaconda prompt installieren \"**conda install scikit-image**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e496bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "from skimage import data, io, exposure, filters\n",
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks, hog, corner_fast, match_descriptors, plot_matched_features\n",
    "from skimage.feature import haar_like_feature_coord, haar_like_feature, draw_haar_like_feature\n",
    "from skimage.transform import warp, AffineTransform, rescale, resize\n",
    "from skimage.draw import ellipse\n",
    "from scipy.ndimage import gaussian_filter, convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe5a47",
   "metadata": {},
   "source": [
    "## Harris Corner Detector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84411588-fc86-4c7c-8cb8-6a1af50d38f6",
   "metadata": {},
   "source": [
    "### Schritt-f√ºr-Schritt-Implementierung \n",
    "\n",
    "Als erstes sollt ihr mit Hilfe des unten stehenden Kochrezepts jeden einzelnen Schritt der Harris-Funktion implementieren.\n",
    "\n",
    "**Ziele**:\n",
    "\n",
    "- Im Zuge der Bearbeitung dieser Aufgabe soll ein tieferes Verst√§ndnis der Funktionsweise des Harris Corner Detektors erlangt werden.\n",
    "- Zudem soll Implementierung von parziellen Ableitungen, Strukturmatrix, Determinante und Matrizenoperationen mit Hilfe von Python-Modulen ge√ºbt werden.\n",
    "\n",
    "Dieses **Kochrezept** k√∂nnt ihr f√ºr Schritt-f√ºr-Schritt-Implementierung der Harris-Funktion nutzen, um die Umsetzung von mathematischen Konzepten wie z.B. parzielle Ableitungen, Strukturmatrix, Determinante und Matrizenoperationen mit Hilfe von Python-Modulen zu √ºben.\n",
    "\n",
    "0. Input: ein Grauwertbild S=(s(x, y)) \n",
    "1. Berechne die partiellen Ableitungen s_x (x, y) und s_y (x, y) (z.B. mit dem Sobel-Operator) an jedem Bildpunkt s(x, y)\n",
    "2. Bestimme die Strukturmatrix M f√ºr jeden Bildpunkt s(x, y)\n",
    "3. Gl√§tte die Strukturmatrix ùëÄ mit dem Gau√ü-Filter\n",
    "4. Bestimme die Response-Funktion (wird auch als Eckenst√§rke bezeichnet) mithilfe der Strukturmatrix ùëÄ:R=det‚Å°(M)-k‚àôSpur(M)^2\n",
    "5. ‚ÄûNon-maximum suppression‚Äú (optional f√ºr die √úbungsaufgabe)\n",
    "6. Output: Koordinaten der Ecken\n",
    "\n",
    "\n",
    "Mehr Details zum Harris Eckendetektor findet ihr auf S. 346, 16.2.1 Harris Eckendetektor, im [Buch](https://tuudk-berlin.userservices.exlibrisgroup.com/view/action/uresolver.do;jsessionid=C99F04DEAB639A8D4E0F354273A3BB08.app02.eu02.prod.alma.dc03.hosted.exlibrisgroup.com:1801?operation=resolveService&package_service_id=20705780600002884&institutionId=2884&customerId=2880) ‚ÄûBildverarbeitung : Band II des Standardwerks Computergrafik und Bildverarbeitung‚Äú (Nischwitz, A., 2020).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9bfb32-1340-4fea-8dc1-693ca83d0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_corners(img, k=0.04):\n",
    "    \"\"\"\n",
    "    Berechnet die Harris Corner Response Funktion:\n",
    "    R=Det(M)-k(Trace(M)^2)\n",
    "        \n",
    "    Argumente:\n",
    "        img: ein Graustufenbild\n",
    "        k: Empfindlichkeit des Eckendetektors, liegt typischerweise im Bereich [0 0.2]\n",
    "\n",
    "    R√ºckgabe:\n",
    "        harris_resp: Harris Response Bild mit dem shape (height, width)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    height, width = img.shape\n",
    "    window = np.ones((window_size, window_size))\n",
    "\n",
    "    harris_resp = np.zeros((height, width))\n",
    "\n",
    "    dx = filters.sobel_v(img)\n",
    "    dy = filters.sobel_h(img)\n",
    "\n",
    "    ### TO DO:\n",
    "    pass \n",
    "    # Strukturmatrix\n",
    "    # Gaussfilterung\n",
    "    # Determinante\n",
    "    # Spur \n",
    "    # Harris Corner Response Funktion\n",
    "\n",
    "    return harris_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68132e54",
   "metadata": {},
   "source": [
    " Unter folgenden Links fidet ihr die Implementierung der Harris Corner Detector Funktionen in der **scikit-image**-Bibliothek ([Corner Detection](https://scikit-image.org/docs/0.17.x/auto_examples/features_detection/plot_corner.html?highlight=corner%20detection)) und in der **OpenCV**-Bibliothek ([Harris Corner Detection](https://docs.opencv.org/3.4/dc/d0d/tutorial_py_features_harris.html)). \n",
    "\n",
    "F√ºhrt Harris Corner Detection mit Hilfe der in diesen Bibliotheken enthaltenen Funktionen durch und vergleicht die Ergebnisse eurer Implementierung mit den Ergebnissen, die ihr mit den bereitgestellten Funktionen bekommt. Stellt ihr Unterschiede fest, versucht diese zu deuten. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77974ab1",
   "metadata": {},
   "source": [
    "## HOG (Histogram of Oriented Gradients)\n",
    "\n",
    "Berechnet f√ºr 2-3 Bilder HOG-Features mit der in der scikit-image-Bibliothek implementierten hog-Funktion und visualisiert die berechneten Features.\n",
    "Verwendet zun√§chst Defaultparameter der HOG-Funktion. \n",
    "√úberlegt euch anschlie√üend, welche Parameter angepasst werden k√∂nnen, um das Ergebnis zu optimieren. Berechnet HOG-Features mit angepassten Parametern und vergleicht die Ergebnisse. \n",
    "\n",
    "**Kontrollfrage**: Wie wird die Gr√∂√üe des HOG-Feature-Vektors festgelegt bzw. Wovon h√§ngt sie ab?\n",
    "\n",
    "Theoretische Grundlagen: \n",
    "Zus√§tzlich zu den in der Vorlesung vermittelten theoretischen Grundlagen k√∂nnt ihr euch das Kapitel 16.3.3 HOG - Histogram of Oriented Gradients S. 362 im [Buch](https://tuudk-berlin.userservices.exlibrisgroup.com/view/action/uresolver.do;jsessionid=C99F04DEAB639A8D4E0F354273A3BB08.app02.eu02.prod.alma.dc03.hosted.exlibrisgroup.com:1801?operation=resolveService&package_service_id=20705780600002884&institutionId=2884&customerId=2880) ‚ÄûBildverarbeitung : Band II des Standardwerks Computergrafik und Bildverarbeitung‚Äú (Nischwitz, A., 2020) anschauen.\n",
    "<img src=\"./ipynb_bilder/hog.png\" alt=\"Alternative text\" />\n",
    "\n",
    "Die **scikit-image**-Implementierung findet ihr unter den folgenden Links:\n",
    "- [Histogram of Oriented Gradients](https://scikit-image.org/docs/0.17.x/auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py)\n",
    "- [API reference for HOG](https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog)\n",
    "- [Ein Beispiel mit Code f√ºr ein tieferes Verst√§ndnis](https://www.thepythoncode.com/article/hog-feature-extraction-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf44ec-1aa8-4347-9487-757996df1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hier kommt euer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511d1a0-693c-4306-9813-8cff37afeba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e626c03-d719-494e-917d-48e9dc6c3c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbbfd1-f0a1-4f8d-a958-df9f0c5f98f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "972a71d6",
   "metadata": {},
   "source": [
    "## SIFT (Scale-Invariant Feature Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e75e5",
   "metadata": {},
   "source": [
    "Berechnet f√ºr 2-3 Bilder SIFT-Features mit der in der OpenCV-Bibliothek implementierten sift-Funktion und visualisiert die berechneten Features.\n",
    "Verwendet zun√§chst Defaultparameter der sift-Funktion. \n",
    "√úbeerlegt euch anschlie√üend, welche Parameter und angepasst werden k√∂nnen, um das Ergebnis zu optimieren. Berechnet sift-Features mit angepassten Parametern und vergleicht die Ergebnisse. \n",
    "\n",
    "**Kontrollfrage**: Kann die Gr√∂√üe des Descriptors variert werden? Wenn die Antwort ist \"ja\", wie, wenn die Antwort ist \"nein\" warum?\n",
    "\n",
    "Theoretische Grundlagen: \n",
    "Zus√§tzlich zu den in der Vorlesung vermittelten theoretischen Grundlagen k√∂nnt ihr euch das Kapitel 16.3.1 SIFT - Scale Invariant Feature Transform S. 351 im [Buch](https://tuudk-berlin.userservices.exlibrisgroup.com/view/action/uresolver.do;jsessionid=C99F04DEAB639A8D4E0F354273A3BB08.app02.eu02.prod.alma.dc03.hosted.exlibrisgroup.com:1801?operation=resolveService&package_service_id=20705780600002884&institutionId=2884&customerId=2880) ‚ÄûBildverarbeitung : Band II des Standardwerks Computergrafik und Bildverarbeitung‚Äú (Nischwitz, A., 2020) anschauen.\n",
    "<img src=\"./ipynb_bilder/sift.png\" alt=\"Alternative text\" />\n",
    "\n",
    "Die **openCV**-Implementierung findet ihr unter dem folgenden Link [Introduction to SIFT](https://docs.opencv.org/3.4/da/df5/tutorial_py_sift_intro.html).\n",
    "[Ein Beispiel mit Code f√ºr ein tieferes Verst√§ndnis](https://www.thepythoncode.com/article/sift-feature-extraction-using-opencv-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807cf18b-88c2-4882-a647-19d530ca5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hier kommt euer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0121c8f-fa59-4cdd-b7ff-db0e7867c672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f69d7-1174-4133-8a40-c4976a7bbf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea26d16-1d8b-4aed-82eb-a0500f532166",
   "metadata": {},
   "source": [
    "## Bonus - Feature Matching\n",
    "Das Ziel ist die Features, die aus zwei Bildern extrahiert wurden, zuzuordnen. Daf√ºr gibt es unterschiedliche Methoden. \n",
    "Unter folgendem [Link](https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html) findet ihr eine Dokumentation dazu (OpenCV-Bibliothek). \n",
    "\n",
    "Anbei ein Beispiel, welches mit dem **Brute-Force Matcher** unter Nutzung der Defayult-Parameter generiert wurde. Das Prinzip des Brute-Force Matchers ist einfach und basiert auf der Berechnung des Abstandes (z.B. L2-Norm) zwischen den Keypoints und Bestimmung des minimalen Abstandes. \n",
    "Ihr k√∂nnt gerne versuchen den Brute-Forse Matcher f√ºr die sift-Deskriptoren der Zangenbilder (Industrial-5.jpg und Industrial-8.jpg) anzuwenden oder ein anderes Bilderpaar aus dem Ordner \"Bilder\" verwenden. \n",
    "<img src=\"./ipynb_bilder/bfmatcher.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21618b3b-01c3-4c1c-ad63-63b31e0c71cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
